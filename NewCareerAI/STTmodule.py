import sounddevice as sd
import numpy as np
from scipy.io.wavfile import write
import whisper
import queue

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
RATE = 16000
CHUNK = 1024
SILENCE_THRESHOLD = 500
SILENCE_DURATION = 5  # ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏á‡∏µ‡∏¢‡∏ö -> ‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Whisper
whisper_model = whisper.load_model("medium")


def record_voice(filename="recorded.wav"):
    """
    ‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏ï‡∏≤‡∏° SILENCE_DURATION
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á
    """
    print("üé§ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á... ‡∏û‡∏π‡∏î‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢")
    q = queue.Queue()
    recording = []

    def callback(indata, frames, time_info, status):
        if status:
            print(status)
        q.put(indata.copy())

    silent_chunks = 0
    with sd.InputStream(samplerate=RATE, channels=1, callback=callback, blocksize=CHUNK):
        while True:
            chunk_data = q.get()
            recording.append(chunk_data)
            amplitude = np.max(np.abs(chunk_data))
            if amplitude < SILENCE_THRESHOLD:
                silent_chunks += 1
            else:
                silent_chunks = 0
            if silent_chunks * CHUNK / RATE >= SILENCE_DURATION:
                break

    audio = np.concatenate(recording, axis=0)
    audio = np.int16(audio / np.max(np.abs(audio)) * 32767)
    write(filename, RATE, audio)
    print("‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
    return filename


def transcribe_voice(filename):
    """
    ‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    """
    print("üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á...")
    result = whisper_model.transcribe(filename, language="th")
    text = result["text"]
    print("üìú ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ:", text)
    return text
