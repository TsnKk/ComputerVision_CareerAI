#!/usr/bin/env python3
"""
üé§ STTmodule.py - Advanced Speech-to-Text Processing System
===========================================================
‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å:
- OpenAI Whisper integration ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
- Real-time voice recording ‡∏î‡πâ‡∏ß‡∏¢ silence detection
- Multi-threaded audio processing ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
- Automatic timeout ‡πÅ‡∏•‡∏∞ error handling
- Support ‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á

‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ:
- WhisperSTT class: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£
- Voice activity detection (VAD)
- Auto-silence detection ‡πÅ‡∏•‡∏∞‡∏´‡∏¢‡∏∏‡∏î‡∏≠‡∏±‡∏î‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
- Real-time microphone selection
- Audio file format conversion
- Threaded recording for non-blocking operation

‡πÇ‡∏°‡πÄ‡∏î‡∏• Whisper:
- tiny, base, small, medium, large (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏î‡πâ)
- Multi-language support
- High accuracy transcription
- Local processing (no internet required)

‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô: from modules.STTmodule import WhisperSTT
===========================================================
"""
import sounddevice as sd
import numpy as np
from scipy.io.wavfile import write
import whisper
import streamlit as st
import streamlit as st
import queue
import os
import time
import threading
from typing import Optional, Tuple, Dict
from pathlib import Path

try:
    from .config import audio_config, whisper_config, AUDIO_DIR, TEMP_DIR
except ImportError:
    from config import audio_config, whisper_config, AUDIO_DIR, TEMP_DIR


# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö (‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å config)
RATE = audio_config.SAMPLE_RATE
CHUNK = audio_config.CHUNK_SIZE  
SILENCE_THRESHOLD = audio_config.SILENCE_THRESHOLD
SILENCE_DURATION = audio_config.SILENCE_DURATION
MIN_RECORDING_DURATION = audio_config.MIN_RECORDING_DURATION
MAX_RECORDING_DURATION = audio_config.MAX_RECORDING_DURATION

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô cache ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Whisper
@st.cache_resource
def get_whisper_model(model_size):
    print(f"üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Whisper ({model_size})...")
    try:
        model = whisper.load_model(model_size)
        print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Whisper ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        return model
    except Exception as e:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Whisper: {e}")
        return None

class WhisperSTT:
    """Enhanced Whisper Speech-to-Text Class"""
    

    def __init__(self, model_size: str = None):
        """
        Initialize Whisper STT
        Args:
            model_size: ‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• (tiny, base, small, medium, large)
        """
        self.model_size = model_size or whisper_config.MODEL_SIZE
        self.model = get_whisper_model(self.model_size)
        self.is_recording = False
    
    def is_ready(self) -> bool:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        return self.model is not None


    def record_voice(self, filename: Optional[str] = None, max_duration: Optional[int] = None) -> Optional[str]:
        """
        ‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏á‡∏µ‡∏¢‡∏ö
        
        Args:
            filename: ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á (optional)
            max_duration: ‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏±‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
            
        Returns:
            path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á ‡∏´‡∏£‡∏∑‡∏≠ None ‡∏´‡∏≤‡∏Å‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
        """
        if not self.is_ready():
            print("‚ùå ‡πÇ‡∏°‡πÄ‡∏î‡∏• Whisper ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            return None
        
        if filename is None:
            timestamp = int(time.time())
            filename = TEMP_DIR / f"recorded_{timestamp}.wav"
        else:
            filename = Path(filename)
        
        max_dur = max_duration or MAX_RECORDING_DURATION
        
        print("üé§ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á... (‡∏û‡∏π‡∏î‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)")
        print(f"   - ‡∏à‡∏∞‡∏´‡∏¢‡∏∏‡∏î‡∏≠‡∏±‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏á‡∏µ‡∏¢‡∏ö {SILENCE_DURATION} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
        print(f"   - ‡∏≠‡∏±‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î {max_dur} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
        print(f"   - ‡∏Å‡∏î Ctrl+C ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö")
        
        self.is_recording = True
        recording_queue = queue.Queue()
        recording_data = []
        silent_chunks = 0
        total_chunks = 0
        start_time = time.time()

        def callback(indata, frames, time_info, status):
            if status:
                print(f"‚ö†Ô∏è Audio callback status: {status}")
            recording_queue.put(indata.copy())

        try:
            with sd.InputStream(samplerate=RATE, channels=1, callback=callback, blocksize=CHUNK):
                while self.is_recording:
                    try:
                        chunk_data = recording_queue.get(timeout=1.0)
                    except queue.Empty:
                        continue
                        
                    recording_data.append(chunk_data)
                    total_chunks += 1
                    
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á
                    amplitude = np.max(np.abs(chunk_data))
                    
                    if amplitude < SILENCE_THRESHOLD:
                        silent_chunks += 1
                    else:
                        silent_chunks = 0

                    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ó‡∏∏‡∏Å‡πÜ 0.5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ 
                    if total_chunks % 8 == 0:
                        duration = total_chunks * CHUNK / RATE
                        print(f"‚è±Ô∏è  ‡∏≠‡∏±‡∏î‡πÅ‡∏•‡πâ‡∏ß {duration:.1f}s (‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {amplitude:.0f})")

                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡∏´‡∏¢‡∏∏‡∏î‡∏≠‡∏±‡∏î
                    recording_duration = total_chunks * CHUNK / RATE
                    silent_duration = silent_chunks * CHUNK / RATE
                    
                    # ‡∏´‡∏¢‡∏∏‡∏î‡∏ñ‡πâ‡∏≤‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏£‡∏ö‡πÄ‡∏ß‡∏•‡∏≤ ‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏î‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
                    if (silent_duration >= SILENCE_DURATION and 
                        recording_duration >= MIN_RECORDING_DURATION):
                        break
                    
                    # ‡∏´‡∏¢‡∏∏‡∏î‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
                    if recording_duration >= max_dur:
                        print(f"‚è∞ ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏î‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ({max_dur}s)")
                        break

        except KeyboardInterrupt:
            print("\n‚èπÔ∏è  ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏î‡∏î‡πâ‡∏ß‡∏¢‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ")
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {e}")
            return None
        finally:
            self.is_recording = False

        if not recording_data:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
            return None

        try:
            # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö
            audio = np.concatenate(recording_data, axis=0)
            
            # Normalize audio
            if np.max(np.abs(audio)) > 0:
                audio = audio / np.max(np.abs(audio))
                audio = np.int16(audio * 32767)
            else:
                print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
                return None
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
            write(str(filename), RATE, audio)
            duration = len(audio) / RATE
            print(f"‚úÖ ‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à: {filename} ({duration:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)")
            
            return str(filename)
            
        except Exception as e:
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {e}")
            return None

    def transcribe_voice(self, filename: str) -> Optional[str]:
        """
        ‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ Whisper
        
        Args:
            filename: ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏õ‡∏•‡∏á
            
        Returns:
            ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡∏≠‡∏î‡πÑ‡∏î‡πâ ‡∏´‡∏£‡∏∑‡∏≠ None ‡∏´‡∏≤‡∏Å‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
        """
        if not self.is_ready():
            print("‚ùå ‡πÇ‡∏°‡πÄ‡∏î‡∏• Whisper ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            return None
            
        if not os.path.exists(filename):
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {filename}")
            return None

        print(f"üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå: {filename}")
        
        try:
            start_time = time.time()
            result = self.model.transcribe(
                filename, 
                language=whisper_config.LANGUAGE,
                temperature=whisper_config.TEMPERATURE
            )
            
            process_time = time.time() - start_time
            
            if result and "text" in result:
                text = result["text"].strip()
                if text:
                    print(f"‚úÖ ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ({process_time:.1f}s)")
                    print(f"üìù ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text}")
                    return text
                else:
                    print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
                    return None
            else:
                print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ")
                return None
                
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {e}")
            return None
    
    def stop_recording(self):
        """‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á"""
        self.is_recording = False
    
    def record_and_transcribe(self, filename: Optional[str] = None, max_duration: Optional[int] = None) -> Tuple[Optional[str], Optional[str]]:
        """
        ‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        
        Returns:
            (audio_file, transcribed_text)
        """
        audio_file = self.record_voice(filename, max_duration)
        if audio_file:
            text = self.transcribe_voice(audio_file)
            return audio_file, text
        return None, None

# ‡∏™‡∏£‡πâ‡∏≤‡∏á instance ‡∏´‡∏•‡∏±‡∏Å
whisper_stt = WhisperSTT()

# Legacy functions ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö backward compatibility
def record_voice(filename="recorded.wav"):
    """Legacy function - ‡πÉ‡∏ä‡πâ WhisperSTT instance"""
    return whisper_stt.record_voice(filename)

def transcribe_voice(filename):
    """Legacy function - ‡πÉ‡∏ä‡πâ WhisperSTT instance"""  
    return whisper_stt.transcribe_voice(filename)

def test_microphone():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô"""
    print("üé§ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô...")
    try:
        devices = sd.query_devices()
        print("üì± ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö:")
        for i, device in enumerate(devices):
            if device['max_input_channels'] > 0:
                print(f"  {i}: {device['name']}")
        
        default_input = sd.default.device[0] if sd.default.device[0] else 0
        print(f"üéØ ‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô‡∏´‡∏•‡∏±‡∏Å: {devices[default_input]['name']}")
        return True
        
    except Exception as e:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô: {e}")
        return False

def record_and_transcribe_legacy(filename="recorded.wav"):
    """Legacy function - ‡∏≠‡∏±‡∏î‡πÅ‡∏•‡∏∞‡∏ñ‡∏≠‡∏î‡πÉ‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß"""
    return whisper_stt.record_and_transcribe(filename)

if __name__ == "__main__":
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡∏î‡∏π‡∏•
    print("=== ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Enhanced STTmodule ===")
    
    if not test_microphone():
        exit(1)
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö WhisperSTT class
    stt = WhisperSTT()
    if not stt.is_ready():
        print("‚ùå Whisper STT ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        exit(1)
    
    print("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏î‡πÅ‡∏•‡∏∞‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á...")
    audio_file, text = stt.record_and_transcribe("test_recording.wav")
    
    if audio_file and text:
        print(f"‚úÖ ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö:")
        print(f"   ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {audio_file}")  
        print(f"   ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text}")
    else:
        print("‚ùå ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß")
