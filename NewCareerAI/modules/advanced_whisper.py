import sounddevice as sd
import numpy as np
from scipy.io.wavfile import write
import whisper
import pyttsx3
import queue
import time

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
RATE = 16000       # sample rate
CHUNK = 1024       # ‡∏Ç‡∏ô‡∏≤‡∏î frame
SILENCE_THRESHOLD = 500  # ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏á‡πÑ‡∏°‡∏Ñ‡πå
SILENCE_DURATION = 5     # ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏á‡∏µ‡∏¢‡∏ö -> ‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Whisper
model = whisper.load_model("medium")

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Text-to-Speech ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
def speak(text):
    engine = pyttsx3.init()
    voices = engine.getProperty('voices')
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏ó‡∏¢ macOS (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: Kanya)
    engine.setProperty('voice', 'com.apple.voice.compact.th-TH.Kanya')
    engine.say(text)
    engine.runAndWait()

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏á‡∏µ‡∏¢‡∏ö
def record_voice(filename="recorded.wav"):
    print("üé§ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á... ‡∏û‡∏π‡∏î‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢")
    q = queue.Queue()
    recording = []

    def callback(indata, frames, time_info, status):
        if status:
            print(status)
        q.put(indata.copy())

    with sd.InputStream(samplerate=RATE, channels=1, callback=callback, blocksize=CHUNK):
        silent_chunks = 0
        while True:
            chunk = q.get()
            recording.append(chunk)
            amplitude = np.max(np.abs(chunk))
            if amplitude < SILENCE_THRESHOLD:
                silent_chunks += 1
            else:
                silent_chunks = 0

            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏£‡∏ö SILENCE_DURATION
            if silent_chunks * CHUNK / RATE >= SILENCE_DURATION:
                break

    audio = np.concatenate(recording, axis=0)
    audio = np.int16(audio / np.max(np.abs(audio)) * 32767)
    write(filename, RATE, audio)
    print("‚úÖ ‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß!")

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á
def transcribe_voice(filename="recorded.wav"):
    print("üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á...")
    result = model.transcribe(filename, language="th")
    text = result["text"]
    print("üìú ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ:", text)
    return text

# ================= MAIN =================
if __name__ == "__main__":
    record_voice()
    text = transcribe_voice()
    print("üîä AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏π‡∏î‡∏ã‡πâ‡∏≥...")
    speak(text)
